{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+brxq/owGRrPdNCJdXfae",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiaojx1987/Practice/blob/main/Extract%2C_Transfrom_and_Load_GDP_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "In this practice project, you will put the skills acquired through the course to use and create a complete ETL pipeline for accessing data from a website and processing it to meet the requirements.\n",
        "\n",
        "Project Scenario:\n",
        "An international firm that is looking to expand its business in different countries across the world has recruited you. You have been hired as a junior Data Engineer and are tasked with creating an automated script that can extract the list of all countries in order of their GDPs in billion USDs (rounded to 2 decimal places), as logged by the International Monetary Fund (IMF). Since IMF releases this evaluation twice a year, this code will be used by the organization to extract the information as it is updated.\n",
        "\n",
        "The required data seems to be available on the URL mentioned below:\n",
        "\n",
        "URL\n",
        "```\n",
        "'https://web.archive.org/web/20230902185326/https://en.wikipedia.org/wiki/List_of_countries_by_GDP_%28nominal%29'\n",
        "```\n",
        "\n",
        "The required information needs to be made accessible as a `CSV` file `Countries_by_GDP.csv` as well as a table `Countries_by_GDP` in a database file `World_Economies.db` with attributes `Country` and `GDP_USD_billion`.\n",
        "\n",
        "Your boss wants you to demonstrate the success of this code by running a query on the database table to display only the entries with more than a 100 billion USD economy. Also, you should log in a file with the entire process of execution named `etl_project_log.txt`.\n",
        "\n",
        "You must create a Python code `etl_project_gdp.py` that performs all the required tasks.\n",
        "\n",
        "# Objectives\n",
        "You have to complete the following tasks for this project\n",
        "\n",
        "1. Write a data extraction function to retrieve the relevant information from the required URL.\n",
        "2. Transform the available GDP information into 'Billion USD' from 'Million USD'.\n",
        "3. Load the transformed information to the required CSV file and as a database file.\n",
        "4. Run the required query on the database.\n",
        "5. Log the progress of the code with appropriate timestamps."
      ],
      "metadata": {
        "id": "8_-FgWTnVjC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "JM9ABqrvWLr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code structure\n",
        "The code should be created in an organized manner such that you can perform each task with a dedicated function. For reference, you can copy paste the structure as shown below to `etl_project_gdp.py`."
      ],
      "metadata": {
        "id": "nU9V3-LZVmjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for ETL operations on Country-GDP data\n",
        "\n",
        "# Importing the required libraries\n",
        "\n",
        "def extract(url, table_attribs):\n",
        "    ''' This function extracts the required\n",
        "    information from the website and saves it to a dataframe. The\n",
        "    function returns the dataframe for further processing. '''\n",
        "\n",
        "    return df\n",
        "\n",
        "def transform(df):\n",
        "    ''' This function converts the GDP information from Currency\n",
        "    format to float value, transforms the information of GDP from\n",
        "    USD (Millions) to USD (Billions) rounding to 2 decimal places.\n",
        "    The function returns the transformed dataframe.'''\n",
        "\n",
        "    return df\n",
        "\n",
        "def load_to_csv(df, csv_path):\n",
        "    ''' This function saves the final dataframe as a `CSV` file\n",
        "    in the provided path. Function returns nothing.'''\n",
        "\n",
        "def load_to_db(df, sql_connection, table_name):\n",
        "    ''' This function saves the final dataframe as a database table\n",
        "    with the provided name. Function returns nothing.'''\n",
        "\n",
        "def run_query(query_statement, sql_connection):\n",
        "    ''' This function runs the stated query on the database table and\n",
        "    prints the output on the terminal. Function returns nothing. '''\n",
        "\n",
        "def log_progress(message):\n",
        "    ''' This function logs the mentioned message at a given stage of the code execution to a log file. Function returns nothing'''\n",
        "\n",
        "''' Here, you define the required entities and call the relevant\n",
        "functions in the correct order to complete the project. Note that this\n",
        "portion is not inside any function.'''"
      ],
      "metadata": {
        "id": "jbCEkB9lvdKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Further, you need to initialize all the known entities. These are mentioned below:\n",
        "\n",
        "URL:\n",
        "```\n",
        "'https://web.archive.org/web/20230902185326/https://en.wikipedia.org/wiki/List_of_countries_by_GDP_%28nominal%29'\n",
        "```\n",
        "\n",
        "table_attribs: The attributes or column names for the dataframe stored as a list. Since the data available in the website is in USD Millions, the attributes should initially be `Country` and `GDP_USD_millions`. This will be modified in the transform function later.\n",
        "\n",
        "`db_name`: As mentioned in the Project scenario, `World_Economies.db`\n",
        "\n",
        "`table_name`: As mentioned in the Project scenario, `Countries_by_GDP`\n",
        "\n",
        "`csv_path`: As mentioned in the Project scenario, `Countries_by_GDP.csv`\n",
        "\n",
        "You should log the initialization process\n",
        "\n",
        "Click here for solution"
      ],
      "metadata": {
        "id": "09J8x2Cxv_Vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://web.archive.org/web/20230902185326/https://en.wikipedia.org/wiki/List_of_countries_by_GDP_%28nominal%29'\n",
        "table_attribs = [\"Country\", \"GDP_USD_millions\"]\n",
        "db_name = 'World_Economies.db'\n",
        "table_name = 'Countries_by_GDP'\n",
        "csv_path = './Countries_by_GDP.csv'"
      ],
      "metadata": {
        "id": "jycIhWO8wP8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Extracting information\n",
        "Extraction of information from a web page is done using the web scraping process. For this, you'll have to analyze the link and come up with the strategy of how to get the required information. The following points are worth observing for this task.\n",
        "\n",
        "1. Inspect the URL and note the position of the table. Note that even the images with captions in them are stored in tabular format. Hence, in the given webpage, our table is at the third position, or index 2. Among this, we require the entries under 'Country/Territory' and 'IMF -> Estimate'.\n",
        "\n",
        "2. Note that there are a few entries in which the IMF estimate is shown to be '—'. Also, there is an entry at the top named 'World', which we do not require. Segregate this entry from the others because this entry does not have a hyperlink and all others in the table do. So you can take advantage of that and access only the rows for which the entry under 'Country/Terriroty' has a hyperlink associated with it.\n",
        "\n",
        "Note that '—' is a special character and not a general hyphen, '-'. Copy the character from the instructions here to use in the code.\n",
        "\n",
        "Assuming the function gets the URL and the table_attribs parameters as arguments, complete the function `extract()` in the code following the steps below.\n",
        "\n",
        "1. Extract the web page as text.\n",
        "    *Use the 'requests.get()' function with 'text' attribute.*\n",
        "\n",
        "2. Parse the text into an HTML object.\n",
        "    *Use the 'BeautifulSoup()' function with the 'html.parser' argument.*\n",
        "\n",
        "3. Create an empty pandas DataFrame named `df` with columns as the table_attribs.\n",
        "    *Use the 'pandas.DataFrame' function with the 'column' argument set as table_attribs.*\n",
        "\n",
        "4. Extract all 'tbody' attributes of the HTML object and then extract all the rows of the index 2 table using the 'tr' attribute.\n",
        "    *Use the 'find_all()' function of the HTML object to gather all attributes of specific type.*\n",
        "\n",
        "5. Check the contents of each row, having attribute `td`, for the following conditions.a.The row should not be empty.b.The first column should contain a hyperlink.c.The third column should not be '—'.\n",
        "  *Run a for loop and check the conditions using if statements.*\n",
        "\n",
        "6. Store all entries matching the conditions in step 5 to a dictionary with keys the same as entries of table_attribs. Append all these dictionaries one by one to the dataframe.*\n",
        "  *You'll need the pandas.concat() function to append the dictionary. Remember to keep the ignore_index parameter as 'True'.*"
      ],
      "metadata": {
        "id": "95KsufZDzh85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract(url, table_attribs):\n",
        "    page = requests.get(url).text\n",
        "    data = BeautifulSoup(page,'html.parser')\n",
        "    df = pd.DataFrame(columns=table_attribs)\n",
        "    tables = data.find_all('tbody')\n",
        "    rows = tables[2].find_all('tr')\n",
        "    for row in rows:\n",
        "        col = row.find_all('td')\n",
        "        if len(col)!=0:\n",
        "            if col[0].find('a') is not None and '—' not in col[2]:\n",
        "                data_dict = {\"Country\": col[0].a.contents[0],\n",
        "                             \"GDP_USD_millions\": col[2].contents[0]}\n",
        "                df1 = pd.DataFrame(data_dict, index=[0])\n",
        "                df = pd.concat([df,df1], ignore_index=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "-1F3dYsBzQq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Transform information\n",
        "The transform function needs to modify the ‘GDP_USD_millions’. You need to cover the following points as a part of the transformation process.\n",
        "\n",
        "1. Convert the contents of the 'GDP_USD_millions' column of df dataframe from currency format to floating numbers.\n",
        " *a. Save the dataframe column as a list. b. Iterate over the contents of the list and use split() and join() functions to convert the currency text into numerical text. Type cast the numerical text to float.*\n",
        "\n",
        "2. Divide all these values by 1000 and round it to 2 decimal places.\n",
        "  *Use the numpy.round() function for rounding. Assign the modified list back to the dataframe.*\n",
        "\n",
        "3. Modify the name of the column from 'GDP_USD_millions' to 'GDP_USD_billions'.\n",
        "  *You'll need the df.rename() function.*\n"
      ],
      "metadata": {
        "id": "2jIOMKEV1iP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(df):\n",
        "    GDP_list = df[\"GDP_USD_millions\"].tolist()\n",
        "    GDP_list = [float(\"\".join(x.split(','))) for x in GDP_list]\n",
        "    GDP_list = [np.round(x/1000,2) for x in GDP_list]\n",
        "    df[\"GDP_USD_millions\"] = GDP_list\n",
        "    df=df.rename(columns = {\"GDP_USD_millions\":\"GDP_USD_billions\"})\n",
        "    return df"
      ],
      "metadata": {
        "id": "ZFxAep-A1ZJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3: Loading information\n",
        "Loading process for this project is two fold.\n",
        "\n",
        "1. You have to save the transformed dataframe to a CSV file. For this, pass the dataframe `df` and the CSV file path to the function `load_to_csv()` and add the required statements there.\n",
        "  *Use the 'to_csv()' function object for the pandas dataframe.*\n"
      ],
      "metadata": {
        "id": "74gXHhtC2CWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_to_csv(df, csv_path):\n",
        "    df.to_csv(csv_path)"
      ],
      "metadata": {
        "id": "qJiB0faH18RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. You have to save the transformed dataframe as a table in the database. This needs to be implemented in the function `load_to_db()`, which accepts the dataframe `df`, the connection object to the SQL database `conn`, and the table name variable `table_name` to be used.\n",
        "\n",
        "  *Use the 'to_sql()' function object for the pandas dataframe.*\n"
      ],
      "metadata": {
        "id": "5va5J2dy2XlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_to_db(df, sql_connection, table_name):\n",
        "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)"
      ],
      "metadata": {
        "id": "vkbQlSEm2Xa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4: Querying the database table\n",
        "Assuming that the appropriate query was initiated and the query statement has been passed to the function run_query(), along with the SQL connection object sql_connection and the table name variable table_name, this function should run the query statement on the table and retrieve the output as a filtered dataframe. This dataframe can then be simply printed.\n",
        "  *Use the pandas.read_sql() function to run the query on the database table.*\n"
      ],
      "metadata": {
        "id": "GSijliVM26d9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_query(query_statement, sql_connection):\n",
        "    print(query_statement)\n",
        "    query_output = pd.read_sql(query_statement, sql_connection)\n",
        "    print(query_output)"
      ],
      "metadata": {
        "id": "NzkImc143EGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 5: Logging progress\n",
        "Logging needs to be done using the `log_progress()` funciton. This function will be called multiple times throughout the execution of this code and will be asked to add a log entry in a .txt file, `etl_project_log.txt`. The entry is supposed to be in the following format:\n",
        "\n",
        "`<Time_stamp> : <message_text>`\n",
        "\n",
        "Here, message text is passed to the function as an argument. Each entry must be in a separate line.\n",
        "  *Use datetime.now() function to get the current timestamp.*\n"
      ],
      "metadata": {
        "id": "SrJXLtVq3I1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_progress(message):\n",
        "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n",
        "    now = datetime.now() # get current timestamp\n",
        "    timestamp = now.strftime(timestamp_format)\n",
        "    with open(\"./etl_project_log.txt\",\"a\") as f:\n",
        "        f.write(timestamp + ' : ' + message + '\\n')"
      ],
      "metadata": {
        "id": "EU8Tyd9p3FU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function calls\n",
        "Now, you have to set up the sequence of function calls for your assigned tasks. Follow the sequence below.\n",
        "\n",
        "|Task\t|Log message on completion|\n",
        "|:-|:-|\n",
        "|Declaring known values\t|Preliminaries complete. Initiating ETL process.|\n",
        "|Call extract() function\t|Data extraction complete. Initiating Transformation process.|\n",
        "|Call transform() function\t|Data transformation complete. Initiating loading process.|\n",
        "|Call load_to_csv()\t|Data saved to CSV file.|\n",
        "|Initiate SQLite3 connection|\tSQL Connection initiated.|\n",
        "|Call load_to_db()\t|Data loaded to Database as table. Running the query.|\n",
        "|Call run_query() *\t|Process Complete.|\n",
        "|Close SQLite3 connection\t|-"
      ],
      "metadata": {
        "id": "qvXg7tC63hhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_progress('Preliminaries complete. Initiating ETL process')\n",
        "\n",
        "df = extract(url, table_attribs)\n",
        "\n",
        "log_progress('Data extraction complete. Initiating Transformation process')\n",
        "\n",
        "df = transform(df)\n",
        "\n",
        "log_progress('Data transformation complete. Initiating loading process')\n",
        "\n",
        "load_to_csv(df, csv_path)\n",
        "\n",
        "log_progress('Data saved to CSV file')\n",
        "\n",
        "sql_connection = sqlite3.connect('World_Economies.db')\n",
        "\n",
        "log_progress('SQL Connection initiated.')\n",
        "\n",
        "load_to_db(df, sql_connection, table_name)\n",
        "\n",
        "log_progress('Data loaded to Database as table. Running the query')\n",
        "\n",
        "query_statement = f\"SELECT * from {table_name} WHERE GDP_USD_billions >= 100\"\n",
        "run_query(query_statement, sql_connection)\n",
        "\n",
        "log_progress('Process Complete.')\n",
        "\n",
        "sql_connection.close()"
      ],
      "metadata": {
        "id": "DrsITXM23vCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################################################"
      ],
      "metadata": {
        "id": "aM_0jc1fFQqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import sqlite3\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "GrjsuHqPFSmp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "D2MJ66amF3g1",
        "outputId": "52667e89-2353-4586-d06c-bc3f974397f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://web.archive.org/web/20230902185326/https://en.wikipedia.org/wiki/List_of_countries_by_GDP_%28nominal%29'\n",
        "path = '\\comtent'\n",
        "table_attribs = ['Country', 'GDP_USD_millions']\n",
        "db_name = 'World_Economies.db'\n",
        "table_name = 'Countries_by_GDP'\n",
        "csv_path = './Countries_by_GDP.csv'"
      ],
      "metadata": {
        "id": "CR2hKuFiFqns"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract(url, table_attribs):\n",
        "  html_page = requests.get(url).text\n",
        "  data = BeautifulSoup(html_page, 'html.parser')\n",
        "  df = pd.DataFrame(columns=table_attribs)\n",
        "  tables = data.find_all('tbody')\n",
        "  rows = tables[2].find_all('tr')\n",
        "  for row in rows:\n",
        "    col = row.find_all('td')\n",
        "    if len(col)!=0:\n",
        "      if col[0].find('a') is not None and '—' not in col[2]:\n",
        "        data_dict = {\"Country\": col[0].a.contents[0],\n",
        "                    \"GDP_USD_millions\": col[2].contents[0]}\n",
        "        df1 = pd.DataFrame(data_dict, index=[0])\n",
        "        df = pd.concat([df,df1], ignore_index=True)\n",
        "  return df\n",
        "\n",
        "\n",
        "def transform(df):\n",
        "  GDP_list = df['GDP_USD_millions'].tolist()\n",
        "  GDP_list = [float(''.join(x.split(','))) for x in GDP_list]\n",
        "  GDP_list = [np.round(x/1000, 2) for x in GDP_list]\n",
        "  df['GDP_USD_millions'] = GDP_list\n",
        "  df = df.rename(columns={'GDP_USD_millions':'GDP_USD_billions'})\n",
        "  return df\n",
        "\n",
        "\n",
        "def load_to_csv(df, csv_path):\n",
        "  df.to_csv(csv_path)\n",
        "\n",
        "\n",
        "def load_to_db(df, sql_connection, table_name):\n",
        "  df.to_sql(table_name, sql_connection, if_exists='replace', index=False)\n",
        "\n",
        "\n",
        "def run_query(query_statme, sql_connection):\n",
        "  print(query_statement)\n",
        "  query_output = pd.read_sql(query_statement, sql_connection)\n",
        "  print(query_output)\n",
        "\n",
        "\n",
        "def log_progress(message):\n",
        "  timestamp_formate = '%Y-%h-%d-%H:%M:%S'\n",
        "  now = datetime.now()\n",
        "  timestamp = now.strftime(timestamp_formate)\n",
        "  with open('./etl_project_log.txt','a') as f:\n",
        "    f.write(timestamp+':'+message+'\\n')\n"
      ],
      "metadata": {
        "id": "Dk7ns91PGDrM"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_progress('Preliminaries complete. Initiating ETL process')\n",
        "df = extract(url, table_attribs)\n",
        "log_progress('Data extraction complete. Initiating Transformation process')\n",
        "df = transform(df)\n",
        "log_progress('Data transformation complete. Initiating loading process')\n",
        "load_to_csv(df, csv_path)\n",
        "log_progress('Data saved to CSV file')\n",
        "sql_connection = sqlite3.connect('World_Economies.db')\n",
        "log_progress('SQL Connection initiated.')\n",
        "load_to_db(df, sql_connection, table_name)\n",
        "log_progress('Data loaded to Database as table. Running the query')\n",
        "query_statement = f\"SELECT * from {table_name} WHERE GDP_USD_billions >= 100\"\n",
        "run_query(query_statement, sql_connection)\n",
        "log_progress('Process Complete.')\n",
        "sql_connection.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCxrVi6n5TCS",
        "outputId": "247f79a5-1583-445d-863d-25f8c809e1a3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT * from Countries_by_GDP WHERE GDP_USD_billions >= 100\n",
            "          Country  GDP_USD_billions\n",
            "0   United States          26854.60\n",
            "1           China          19373.59\n",
            "2           Japan           4409.74\n",
            "3         Germany           4308.85\n",
            "4           India           3736.88\n",
            "..            ...               ...\n",
            "64          Kenya            118.13\n",
            "65         Angola            117.88\n",
            "66           Oman            104.90\n",
            "67      Guatemala            102.31\n",
            "68       Bulgaria            100.64\n",
            "\n",
            "[69 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lXRw215852DT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}